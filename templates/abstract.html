<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Abstract - Object Detection System</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <style>
        :root {
            --primary-color: #4F46E5;
            --secondary-color: #10B981;
            --accent-color: #4CAF50;
            --text-color: #333;
            --light-text: #fff;
            --card-bg: rgba(255, 255, 255, 0.9);
            --shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            --border-radius: 12px;
            --transition: all 0.3s ease;
            --bg-color: #b92b27;
        }

        body {
            background: #b92b27;  /* fallback for old browsers */
            background: -webkit-linear-gradient(to right, #1565C0, #b92b27);  /* Chrome 10-25, Safari 5.1-6 */
            background: linear-gradient(to right, #1565C0, #b92b27); /* W3C, IE 10+/ Edge, Firefox 16+, Chrome 26+, Opera 12+, Safari 7+ */
            background-size: 300% 300%;
            animation: gradientMove 15s ease infinite;
            min-height: 100vh;
            padding: 20px;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            color: var(--text-color);
            position: relative;
            overflow-x: hidden;
        }

        body::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-image: 
                radial-gradient(circle at 25% 25%, rgba(0, 0, 0, 0.05) 1px, transparent 1px),
                radial-gradient(circle at 75% 75%, rgba(0, 0, 0, 0.05) 1px, transparent 1px);
            background-size: 50px 50px;
            z-index: 0;
            opacity: 0.5;
        }

        @keyframes gradientMove {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
            position: relative;
            z-index: 2;
        }

        .abstract-card {
            background: var(--card-bg);
            backdrop-filter: blur(12px);
            border-radius: var(--border-radius);
            padding: 40px;
            margin-bottom: 40px;
            box-shadow: var(--shadow);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-color);
            transition: var(--transition);
        }

        .abstract-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(79, 70, 229, 0.25);
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
        }

        .header h1 {
            font-size: 2.5rem;
            font-weight: 800;
            margin-bottom: 20px;
            background: linear-gradient(to right, #818CF8, #6EE7B7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 40px;
        }

        .model-card {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 16px;
            padding: 30px;
            text-align: center;
            transition: all 0.3s ease;
            text-decoration: none;
            color: #1E1B4B;
            display: block;
        }

        .model-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(31, 38, 135, 0.2);
            color: #4F46E5;
        }

        .model-card i {
            font-size: 2.5rem;
            margin-bottom: 20px;
            background: linear-gradient(135deg, #4F46E5, #7C3AED);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .model-card h3 {
            font-size: 1.5rem;
            margin-bottom: 10px;
        }

        .model-card p {
            color: #6B7280;
            margin: 0;
            line-height: 1.6;
        }

        .back-button {
            position: relative;
            z-index: 3;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            padding: 12px 24px;
            border-radius: 12px;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: all 0.3s ease;
            margin-bottom: 30px;
            cursor: pointer;
        }

        .back-button:hover {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            transform: translateX(-5px);
        }

        @media (max-width: 768px) {
            .model-grid {
                grid-template-columns: 1fr;
            }
        }

        .model-card.active {
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(31, 38, 135, 0.15);
            margin-bottom: 30px;
        }

        .model-details {
            text-align: left;
            margin-top: 30px;
        }

        .key-metrics {
            display: flex;
            justify-content: space-around;
            margin: 30px 0;
            padding: 20px;
            background: rgba(79, 70, 229, 0.1);
            border-radius: 15px;
        }

        .metric {
            text-align: center;
        }

        .metric h4 {
            color: #4F46E5;
            font-size: 1.8rem;
            margin-bottom: 5px;
        }

        .metric p {
            color: #6B7280;
            font-size: 0.9rem;
            margin: 0;
        }

        .features {
            margin: 30px 0;
        }

        .feature {
            margin-bottom: 20px;
        }

        .feature h5 {
            color: #1E1B4B;
            margin-bottom: 8px;
        }

        .feature p {
            color: #6B7280;
            font-size: 0.95rem;
            line-height: 1.6;
        }

        .technical-details, .use-cases {
            margin: 20px 0;
        }

        .technical-details h5, .use-cases h5 {
            color: #1E1B4B;
            margin-bottom: 10px;
        }

        .technical-details p, .use-cases p {
            color: #6B7280;
            font-size: 0.95rem;
            line-height: 1.6;
        }

        /* Add creative elements */
        .floating-shapes {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            pointer-events: none;
        }

        .shape {
            position: absolute;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 50%;
            animation: floatShape 20s infinite linear;
        }

        .shape.triangle {
            width: 0;
            height: 0;
            background: transparent;
            border-left: 15px solid transparent;
            border-right: 15px solid transparent;
            border-bottom: 30px solid rgba(255, 255, 255, 0.2);
        }

        .shape.square {
            width: 20px;
            height: 20px;
            border-radius: 3px;
        }

        .shape.circle {
            width: 25px;
            height: 25px;
        }

        @keyframes floatShape {
            0% { transform: translate(0, 0) rotate(0deg); opacity: 0; }
            10% { opacity: 0.8; }
            90% { opacity: 0.8; }
            100% { transform: translate(var(--moveX), var(--moveY)) rotate(360deg); opacity: 0; }
        }

        /* Add wave effect */
        .wave {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            z-index: 1;
            pointer-events: none;
        }

        @keyframes waveAnimation {
            0% { background-position-x: 0; }
            100% { background-position-x: 1440px; }
        }

        .model-page {
            display: none;
            background: var(--card-bg);
            backdrop-filter: blur(12px);
            border-radius: var(--border-radius);
            padding: 40px;
            margin-bottom: 40px;
            box-shadow: var(--shadow);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-color);
            transition: var(--transition);
        }

        .model-page.active {
            display: block;
            animation: fadeIn 0.5s ease-in-out;
        }

        .model-nav {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .model-nav-item {
            background: rgba(255, 255, 255, 0.8);
            border-radius: 12px;
            padding: 15px 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            color: var(--text-color);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }

        .model-nav-item:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(79, 70, 229, 0.3);
            border-color: rgba(79, 70, 229, 0.5);
        }

        .model-nav-item.active {
            background: linear-gradient(135deg, #4F46E5, #7C3AED);
            color: white;
            border-color: transparent;
        }

        .model-header {
            display: flex;
            align-items: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .model-icon {
            font-size: 3rem;
            background: linear-gradient(135deg, #4F46E5, #7C3AED);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .model-title {
            font-size: 2.2rem;
            font-weight: 800;
            color: var(--text-color);
            margin: 0;
        }

        .model-subtitle {
            font-size: 1.2rem;
            color: #6B7280;
            margin-top: 5px;
        }

        .model-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
        }

        .model-description {
            line-height: 1.8;
            font-size: 1.1rem;
        }

        .model-features {
            background: rgba(255, 255, 255, 0.5);
            border-radius: 12px;
            padding: 25px;
        }

        .model-feature {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.05);
        }

        .model-feature:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .feature-icon {
            font-size: 1.5rem;
            color: #4F46E5;
        }

        .feature-text {
            flex: 1;
        }

        .feature-title {
            font-weight: 600;
            margin-bottom: 5px;
        }

        .feature-description {
            font-size: 0.95rem;
            color: #6B7280;
        }

        .model-stats {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin-top: 30px;
        }

        .stat-card {
            background: rgba(255, 255, 255, 0.7);
            border-radius: 12px;
            padding: 20px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }

        .stat-value {
            font-size: 2rem;
            font-weight: 700;
            color: #4F46E5;
            margin-bottom: 5px;
        }

        .stat-label {
            font-size: 0.9rem;
            color: #6B7280;
        }

        @media (max-width: 768px) {
            .model-content {
                grid-template-columns: 1fr;
            }
            
            .model-stats {
                grid-template-columns: 1fr;
            }
            
            .model-nav {
                flex-direction: column;
                gap: 10px;
            }
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .model-buttons {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 40px 0;
            flex-wrap: wrap;
        }

        .model-button {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 16px;
            padding: 20px 30px;
            text-align: center;
            transition: all 0.3s ease;
            cursor: pointer;
            color: #1E1B4B;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-width: 200px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        .model-button:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(79, 70, 229, 0.3);
            border-color: rgba(79, 70, 229, 0.5);
        }

        .model-button i {
            font-size: 2.5rem;
            margin-bottom: 15px;
            background: linear-gradient(135deg, #4F46E5, #7C3AED);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .model-button h3 {
            font-size: 1.3rem;
            margin-bottom: 10px;
            font-weight: 600;
        }

        .model-button p {
            color: #6B7280;
            font-size: 0.9rem;
            margin: 0;
        }

        .model-button.active {
            background: linear-gradient(135deg, #4F46E5, #7C3AED);
            color: white;
            border-color: transparent;
        }

        .model-button.active i {
            background: white;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .model-button.active p {
            color: rgba(255, 255, 255, 0.8);
        }

        @media (max-width: 768px) {
            .model-buttons {
                flex-direction: column;
                align-items: center;
            }
            
            .model-button {
                width: 100%;
                max-width: 300px;
            }
        }

        .architecture-section {
            margin-top: 30px;
        }

        .architecture-diagram {
            margin-top: 10px;
        }

        .architecture-diagram img {
            width: 100%;
            height: auto;
            border-radius: 12px;
        }

        .architecture-container {
            background: white;
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .architecture-image {
            width: 100%;
            max-width: 800px;
            height: auto;
            margin: 0 auto;
            display: block;
        }

        .architecture-description {
            margin-top: 20px;
            padding: 20px;
            background: rgba(79, 70, 229, 0.1);
            border-radius: 8px;
        }

        .architecture-description p {
            color: #2d3436;
            font-size: 1.1em;
            margin-bottom: 15px;
            line-height: 1.6;
        }

        .architecture-description ul {
            list-style-type: none;
            padding: 0;
        }

        .architecture-description li {
            margin: 12px 0;
            padding-left: 24px;
            position: relative;
            color: #2d3436;
            line-height: 1.5;
        }

        .architecture-description li:before {
            content: "•";
            color: #4F46E5;
            font-weight: bold;
            position: absolute;
            left: 0;
        }

        .architecture-description strong {
            color: #4F46E5;
        }

        @media (max-width: 768px) {
            .architecture-container {
                padding: 15px;
            }

            .architecture-description {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="floating-shapes" id="floatingShapes"></div>
    <div class="wave"></div>
    <div class="container">
        <a href="/" class="back-button">
            <i class="fas fa-arrow-left"></i>
            Back to Home
        </a>

        <div class="abstract-card">
            <div class="header">
                <h1>Waste Detection System</h1>
                <p class="lead">An Advanced Deep Learning Approach to Environmental Sustainability</p>
            </div>

            <div class="content">
                <p>Our waste detection system employs state-of-the-art deep learning models to accurately identify and classify various types of waste materials in real-time. This project aims to revolutionize waste management by automating the sorting process and improving recycling efficiency.</p>
                
                <p>The system utilizes three distinct deep learning architectures, each optimized for specific use cases and deployment scenarios. From lightweight mobile solutions to high-accuracy industrial applications, our models provide flexible options for various waste detection needs.</p>

                <div class="model-buttons">
                    <div class="model-button active" data-model="overview">
                        <i class="fas fa-info-circle"></i>
                        <h3>Overview</h3>
                        <p>System introduction and features</p>
                    </div>
                    <div class="model-button" data-model="cnn">
                        <i class="fas fa-brain"></i>
                        <h3>CNN Model</h3>
                        <p>Convolutional Neural Network</p>
                    </div>
                    <div class="model-button" data-model="rcnn">
                        <i class="fas fa-object-group"></i>
                        <h3>R-CNN Model</h3>
                        <p>Region-based CNN</p>
                    </div>
                    <div class="model-button" data-model="mobilenet">
                        <i class="fas fa-mobile-alt"></i>
                        <h3>MobileNetV2</h3>
                        <p>Lightweight model for mobile</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="model-page active" id="overview-page">
            <div class="abstract-card">
                <h2>Marine Waste Detection System</h2>
                <p>
                    Our Marine Waste Detection System is an advanced AI-powered solution designed to identify and classify waste materials in marine environments. 
                    This system utilizes state-of-the-art deep learning models to detect various types of waste, including plastics, metals, and other debris, 
                    helping to address the growing problem of marine pollution.
                </p>
                <p>
                    The system is built on a robust architecture that combines multiple deep learning models, each optimized for different aspects of waste detection. 
                    By leveraging the strengths of Convolutional Neural Networks (CNN), Region-based CNNs (R-CNN), and lightweight models like MobileNetV2, 
                    our system provides comprehensive waste detection capabilities across various scenarios and environments.
                </p>

                <div class="architecture-section">
                    <h2 class="section-title">System Architecture</h2>
                    <div class="architecture-container">
                        <svg width="100%" height="900" viewBox="0 0 800 1100" xmlns="http://www.w3.org/2000/svg">
                            <!-- Definitions -->
                            <defs>
                                <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                    <polygon points="0 0, 10 3.5, 0 7" fill="black"/>
                                </marker>
                            </defs>

                            <!-- Title -->
                            <text x="400" y="30" text-anchor="middle" font-size="24" font-weight="bold">Marine Waste Detection System</text>

                            <!-- Upload Image -->
                            <rect x="300" y="80" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="125" text-anchor="middle" font-size="16">Upload Image</text>

                            <!-- Read and Convert -->
                            <rect x="300" y="220" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="255" text-anchor="middle" font-size="16">Read and Convert</text>
                            <text x="400" y="275" text-anchor="middle" font-size="16">Image to RGB</text>

                            <!-- Load Model -->
                            <rect x="300" y="360" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="385" text-anchor="middle" font-size="16">Load Model</text>
                            <text x="400" y="405" text-anchor="middle" font-size="16">(CNN, R-CNN, MobilenetV2)</text>

                            <!-- Object Detection -->
                            <rect x="300" y="500" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="525" text-anchor="middle" font-size="16">Object Detection using</text>
                            <text x="400" y="545" text-anchor="middle" font-size="16">Thresholding and Contours</text>

                            <!-- Decision Diamond -->
                            <path d="M350,640 L400,690 L450,640 L400,590 Z" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="635" text-anchor="middle" font-size="16">No Objects</text>
                            <text x="400" y="655" text-anchor="middle" font-size="16">Detected?</text>

                            <!-- Left Branch: Canny Edge Detection -->
                            <rect x="150" y="740" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="250" y="765" text-anchor="middle" font-size="16">Object Detection</text>
                            <text x="250" y="785" text-anchor="middle" font-size="16">using Canny</text>
                            <text x="250" y="805" text-anchor="middle" font-size="16">Edge Detection</text>

                            <!-- Right Branch: Classify Objects -->
                            <rect x="450" y="740" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="550" y="775" text-anchor="middle" font-size="16">Classify Detected</text>
                            <text x="550" y="795" text-anchor="middle" font-size="16">Objects</text>

                            <!-- Filter by Confidence -->
                            <rect x="300" y="880" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="905" text-anchor="middle" font-size="16">Filter by Confidence</text>
                            <text x="400" y="925" text-anchor="middle" font-size="16">Threshold</text>

                            <!-- Draw Bounding Boxes -->
                            <rect x="300" y="1020" width="200" height="80" rx="5" fill="white" stroke="black" stroke-width="2"/>
                            <text x="400" y="1045" text-anchor="middle" font-size="16">Draw Bounding Boxes</text>
                            <text x="400" y="1065" text-anchor="middle" font-size="16">and Display Results</text>

                            <!-- Vertical Connections -->
                            <!-- Upload to Read -->
                            <line x1="400" y1="160" x2="400" y2="220" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                            <!-- Read to Load -->
                            <line x1="400" y1="300" x2="400" y2="360" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                            <!-- Load to Detection -->
                            <line x1="400" y1="440" x2="400" y2="500" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                            <!-- Detection to Diamond -->
                            <line x1="400" y1="580" x2="400" y2="590" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>

                            <!-- Diamond to Branches -->
                            <!-- Left branch -->
                            <line x1="350" y1="640" x2="250" y2="740" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                            <!-- Right branch -->
                            <line x1="450" y1="640" x2="550" y2="740" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>

                            <!-- Branches to Filter -->
                            <!-- Left to Filter -->
                            <line x1="250" y1="820" x2="400" y2="880" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                            <!-- Right to Filter -->
                            <line x1="550" y1="820" x2="400" y2="880" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>

                            <!-- Filter to Draw -->
                            <line x1="400" y1="960" x2="400" y2="1020" stroke="black" stroke-width="2" marker-end="url(#arrowhead)"/>
                        </svg>
                    </div>
                    <div class="architecture-description mt-4">
                        <p>The Marine Waste Detection System follows a systematic workflow:</p>
                        <ul>
                            <li><strong>Input Processing:</strong> Images are uploaded and converted to RGB format</li>
                            <li><strong>Model Selection:</strong> The system loads one of three deep learning models (CNN, R-CNN, or MobileNetV2)</li>
                            <li><strong>Detection Pipeline:</strong> Uses both thresholding and Canny edge detection for robust object detection</li>
                            <li><strong>Classification:</strong> Detected objects are classified and filtered based on confidence scores</li>
                            <li><strong>Visualization:</strong> Results are displayed with bounding boxes around detected waste objects</li>
                        </ul>
                    </div>
                </div>

                <p>
                    The primary goal of this project is to assist environmental organizations, researchers, and waste management companies in their efforts to 
                    clean up marine environments. By providing accurate and efficient waste detection, our system helps identify polluted areas, track waste 
                    accumulation patterns, and optimize cleanup operations.
                </p>
                <h3>Key Features</h3>
                <ul>
                    <li>Multiple AI models for different detection scenarios</li>
                    <li>Real-time processing capabilities</li>
                    <li>High accuracy in waste classification</li>
                    <li>User-friendly interface for easy operation</li>
                    <li>Detailed analytics and visualization of detection results</li>
                </ul>
                <h3>Applications</h3>
                <p>
                    The Marine Waste Detection System has numerous applications, including:
                </p>
                <ul>
                    <li>Environmental monitoring and assessment</li>
                    <li>Marine cleanup operations</li>
                    <li>Research on marine pollution patterns</li>
                    <li>Educational tools for raising awareness about marine waste</li>
                    <li>Support for policy-making on environmental protection</li>
                </ul>
            </div>
        </div>

        <div class="model-page" id="cnn-page">
            <div class="model-header">
                <div class="model-icon">
                    <i class="fas fa-brain"></i>
                </div>
                <div>
                    <h2 class="model-title">CNN Model</h2>
                    <p class="model-subtitle">Convolutional Neural Network for High-Accuracy Waste Detection</p>
                </div>
            </div>
            
            <div class="model-content">
                <div class="model-description">
                    <p>
                        Our CNN (Convolutional Neural Network) model is the foundation of our waste detection system, providing high accuracy and reliability 
                        in identifying various types of marine waste. This model has been specifically trained on a diverse dataset of marine waste images, 
                        allowing it to recognize subtle patterns and characteristics of different waste materials.
                    </p>
                    <p>
                        The CNN architecture consists of multiple convolutional layers that extract features from input images, followed by pooling layers 
                        that reduce spatial dimensions and enhance important features. The model then uses fully connected layers to classify the detected 
                        objects into waste categories.
                    </p>
                    <p>
                        This model excels in scenarios where high accuracy is paramount, such as detailed waste analysis and research applications. 
                        It can distinguish between different types of plastics, metals, and other debris with remarkable precision, making it an 
                        invaluable tool for environmental monitoring and assessment.
                    </p>
                </div>
                
                <div class="model-features">
                    <h3>Key Features</h3>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-bullseye"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">High Accuracy</div>
                            <div class="feature-description">Achieves 96% accuracy in waste classification across various categories.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-tachometer-alt"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Fast Processing</div>
                            <div class="feature-description">Processes images in approximately 45ms on standard hardware.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-memory"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Moderate Resource Usage</div>
                            <div class="feature-description">Requires approximately 85MB of memory during operation.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-layer-group"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Deep Architecture</div>
                            <div class="feature-description">Utilizes 12 convolutional layers for comprehensive feature extraction.</div>
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="model-stats">
                <div class="stat-card">
                    <div class="stat-value">96%</div>
                    <div class="stat-label">Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">45ms</div>
                    <div class="stat-label">Processing Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">85MB</div>
                    <div class="stat-label">Memory Usage</div>
                </div>
            </div>
            
            <div class="architecture-section">
                <h2 class="section-title">Model Architecture</h2>
                <div class="architecture-container">
                    <img src="{{ url_for('cnn_architecture') }}" alt="CNN Model Architecture" class="architecture-image">
                    <div class="architecture-description">
                        <p>Our CNN model follows a classic deep learning architecture optimized for waste detection:</p>
                        <ul>
                            <li><strong>Input Layer:</strong> Accepts 224×224×3 RGB images</li>
                            <li><strong>Convolutional Layers:</strong> Extract features using multiple convolution operations</li>
                            <li><strong>Pooling Layer:</strong> Reduces spatial dimensions while preserving important features</li>
                            <li><strong>Fully Connected Layer:</strong> Combines high-level features for classification</li>
                            <li><strong>Output Layer:</strong> Produces final classification (Waste/Non-waste)</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <div class="model-page" id="rcnn-page">
            <div class="model-header">
                <div class="model-icon">
                    <i class="fas fa-object-group"></i>
                </div>
                <div>
                    <h2 class="model-title">R-CNN Model</h2>
                    <p class="model-subtitle">Region-based CNN for Multiple Object Detection</p>
                </div>
            </div>
            
            <div class="model-content">
                <div class="model-description">
                    <p>
                        The R-CNN (Region-based Convolutional Neural Network) model in our system is specifically designed for detecting multiple waste objects 
                        within a single image. This model excels in complex scenes where various types of waste are present simultaneously, making it ideal 
                        for comprehensive environmental surveys and assessments.
                    </p>
                    <p>
                        Unlike standard CNNs that classify entire images, R-CNN first identifies regions of interest (ROIs) that may contain waste objects, 
                        then analyzes each region individually. This two-stage approach allows the model to focus on specific areas of the image, improving 
                        detection accuracy for multiple objects.
                    </p>
                    <p>
                        Our implementation of R-CNN has been optimized for marine waste detection, with specialized training on datasets containing various 
                        waste materials in different marine environments. This model is particularly effective in scenarios where multiple waste items are 
                        clustered together or partially obscured.
                    </p>
                </div>
                
                <div class="model-features">
                    <h3>Key Features</h3>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-cubes"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Multiple Object Detection</div>
                            <div class="feature-description">Can identify and classify multiple waste objects in a single image.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-bullseye"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">High Accuracy</div>
                            <div class="feature-description">Achieves 92% accuracy in multi-object waste detection.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-tachometer-alt"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Moderate Processing Speed</div>
                            <div class="feature-description">Processes images in approximately 75ms on standard hardware.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-memory"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Higher Resource Usage</div>
                            <div class="feature-description">Requires approximately 120MB of memory during operation.</div>
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="model-stats">
                <div class="stat-card">
                    <div class="stat-value">92%</div>
                    <div class="stat-label">Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">75ms</div>
                    <div class="stat-label">Processing Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">120MB</div>
                    <div class="stat-label">Memory Usage</div>
                </div>
            </div>
            
            <div class="architecture-section">
                <h2 class="text-center mb-4">RCNN Architecture</h2>
                <div class="architecture-diagram">
                    <svg width="100%" height="400" viewBox="0 0 1000 400" xmlns="http://www.w3.org/2000/svg">
                        <!-- Definitions for gradients and markers -->
                        <defs>
                            <marker id="arrowhead3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="black"/>
                            </marker>
                        </defs>

                        <!-- Input Image -->
                        <rect x="50" y="150" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="110" y="180" text-anchor="middle" fill="white" font-size="24">Input</text>
                        <text x="110" y="210" text-anchor="middle" fill="white" font-size="24">Image</text>

                        <!-- CNN -->
                        <rect x="220" y="150" width="100" height="100" rx="15" fill="#2196F3"/>
                        <text x="270" y="205" text-anchor="middle" fill="white" font-size="24">CNN</text>

                        <!-- Upper Branch -->
                        <!-- RoI Pooling 1 -->
                        <rect x="420" y="50" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="480" y="90" text-anchor="middle" fill="white" font-size="24">RoI</text>
                        <text x="480" y="120" text-anchor="middle" fill="white" font-size="24">Pooling</text>

                        <!-- Fully Connected 1 -->
                        <rect x="600" y="50" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="660" y="90" text-anchor="middle" fill="white" font-size="24">Fully</text>
                        <text x="660" y="120" text-anchor="middle" fill="white" font-size="24">Connected</text>

                        <!-- Classifier -->
                        <rect x="780" y="50" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="840" y="105" text-anchor="middle" fill="white" font-size="24">Classifier</text>

                        <!-- Lower Branch -->
                        <!-- RoI Pooling 2 -->
                        <rect x="420" y="250" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="480" y="290" text-anchor="middle" fill="white" font-size="24">RoI</text>
                        <text x="480" y="320" text-anchor="middle" fill="white" font-size="24">Pooling</text>

                        <!-- Fully Connected 2 -->
                        <rect x="600" y="250" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="660" y="290" text-anchor="middle" fill="white" font-size="24">Fully</text>
                        <text x="660" y="320" text-anchor="middle" fill="white" font-size="24">Connected</text>

                        <!-- Bounding Box -->
                        <rect x="780" y="250" width="120" height="100" rx="15" fill="#2196F3"/>
                        <text x="840" y="280" text-anchor="middle" fill="white" font-size="24">Bounding</text>
                        <text x="840" y="310" text-anchor="middle" fill="white" font-size="24">Box</text>
                        <text x="840" y="340" text-anchor="middle" fill="white" font-size="24">Regressor</text>

                        <!-- Main path -->
                        <path d="M170 200 H220" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        
                        <!-- CNN to RoI Pooling connections -->
                        <!-- Upper branch to first RoI Pooling -->
                        <path d="M320 200 L420 100" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        <!-- Lower branch to second RoI Pooling -->
                        <path d="M320 200 L420 300" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        
                        <!-- Upper branch connections -->
                        <path d="M540 100 H600" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        <path d="M720 100 H780" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        
                        <!-- Lower branch connections -->
                        <path d="M540 300 H600" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                        <path d="M720 300 H780" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>

                        <!-- Vertical connection from Classifier to Bounding Box -->
                        <path d="M840 150 L840 250" stroke="black" stroke-width="2" marker-end="url(#arrowhead3)"/>
                    </svg>
                </div>
                <div class="architecture-description mt-4">
                    <h4>Key Components:</h4>
                    <ul>
                        <li><strong>Input Image:</strong> The raw image input to be processed</li>
                        <li><strong>CNN:</strong> Convolutional Neural Network for feature extraction</li>
                        <li><strong>RoI Pooling:</strong> Region of Interest pooling layers for both classification and localization</li>
                        <li><strong>Fully Connected Layers:</strong> Dense layers for feature processing</li>
                        <li><strong>Classifier:</strong> Final classification of detected objects</li>
                        <li><strong>Bounding Box Regressor:</strong> Precise localization of detected objects</li>
                    </ul>
                    <p class="mt-3">The RCNN architecture employs a two-stream approach: one for classification (upper branch) and one for localization (lower branch). This allows simultaneous object detection and localization, making it particularly effective for identifying waste objects in complex marine environments.</p>
                </div>
            </div>
        </div>

        <div class="model-page" id="mobilenet-page">
            <div class="model-header">
                <div class="model-icon">
                    <i class="fas fa-mobile-alt"></i>
                </div>
                <div>
                    <h2 class="model-title">MobileNetV2</h2>
                    <p class="model-subtitle">Lightweight Model for Mobile and Edge Devices</p>
                </div>
            </div>
            
            <div class="model-content">
                <div class="model-description">
                    <p>
                        MobileNetV2 is a lightweight deep learning model designed specifically for deployment on resource-constrained devices such as 
                        smartphones, tablets, and edge computing devices. This model offers an excellent balance between performance and efficiency, 
                        making it ideal for field applications where computational resources are limited.
                    </p>
                    <p>
                        The architecture of MobileNetV2 is based on depthwise separable convolutions, which significantly reduce the number of parameters 
                        and computational complexity compared to standard convolutional layers. This efficient design allows the model to run smoothly on 
                        mobile devices while still maintaining good accuracy for waste detection tasks.
                    </p>
                    <p>
                        Our implementation of MobileNetV2 has been fine-tuned specifically for marine waste detection, with training on a diverse dataset 
                        of waste images. This model is particularly well-suited for real-time applications in the field, such as monitoring waste accumulation 
                        in marine environments or assisting cleanup operations.
                    </p>
                </div>

                <div class="model-features">
                    <h3>Key Features</h3>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-mobile-alt"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Lightweight Design</div>
                            <div class="feature-description">Optimized for mobile and edge devices with minimal resource usage.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-tachometer-alt"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Fast Processing</div>
                            <div class="feature-description">Processes images in approximately 25ms on standard hardware.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-bullseye"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Good Accuracy</div>
                            <div class="feature-description">Achieves 88% accuracy in waste classification.</div>
                        </div>
                    </div>
                    <div class="model-feature">
                        <div class="feature-icon">
                            <i class="fas fa-memory"></i>
                        </div>
                        <div class="feature-text">
                            <div class="feature-title">Efficient Memory Usage</div>
                            <div class="feature-description">Requires only 45MB of memory during operation.</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="model-stats">
                <div class="stat-card">
                    <div class="stat-value">88%</div>
                    <div class="stat-label">Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">25ms</div>
                    <div class="stat-label">Processing Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">45MB</div>
                    <div class="stat-label">Memory Usage</div>
                </div>
            </div>

            <div class="architecture-section">
                <h2 class="text-center mb-4">MobileNetV2</h2>
                <div class="architecture-diagram">
                    <svg width="100%" height="600" viewBox="0 0 1000 600" xmlns="http://www.w3.org/2000/svg">
                        <!-- Definitions -->
                        <defs>
                            <marker id="arrowhead4" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="black"/>
                            </marker>
                            <linearGradient id="bottleneckGradient" x1="0%" y1="0%" x2="100%" y2="0%">
                                <stop offset="0%" style="stop-color:#E3F2FD;stop-opacity:1" />
                                <stop offset="100%" style="stop-color:#FFF3E0;stop-opacity:1" />
                            </linearGradient>
                        </defs>

                        <!-- Input Layer -->
                        <rect x="50" y="250" width="80" height="100" rx="5" fill="#E3F2FD" stroke="black" stroke-width="2"/>
                        <text x="90" y="300" text-anchor="middle" fill="black" font-size="16">Input</text>

                        <!-- Initial Conv2D -->
                        <rect x="180" y="250" width="100" height="100" rx="5" fill="#FFF3E0" stroke="black" stroke-width="2"/>
                        <text x="230" y="285" text-anchor="middle" fill="black" font-size="16">Conv2D</text>
                        <text x="230" y="305" text-anchor="middle" fill="black" font-size="14">3x3</text>
                        <text x="230" y="325" text-anchor="middle" fill="black" font-size="14">s=2</text>

                        <!-- Bottleneck Block 1 -->
                        <g transform="translate(330,250)">
                            <rect width="140" height="100" rx="5" fill="url(#bottleneckGradient)" stroke="black" stroke-width="2"/>
                            <text x="70" y="35" text-anchor="middle" fill="black" font-size="16">Bottleneck</text>
                            <text x="70" y="55" text-anchor="middle" fill="black" font-size="14">t=1, c=16</text>
                            <text x="70" y="75" text-anchor="middle" fill="black" font-size="14">n=1, s=1</text>
                        </g>

                        <!-- Bottleneck Block 2 -->
                        <g transform="translate(520,250)">
                            <rect width="140" height="100" rx="5" fill="url(#bottleneckGradient)" stroke="black" stroke-width="2"/>
                            <text x="70" y="35" text-anchor="middle" fill="black" font-size="16">Bottleneck</text>
                            <text x="70" y="55" text-anchor="middle" fill="black" font-size="14">t=6, c=24</text>
                            <text x="70" y="75" text-anchor="middle" fill="black" font-size="14">n=2, s=2</text>
                        </g>

                        <!-- Conv2D 1x1 -->
                        <rect x="710" y="250" width="100" height="100" rx="5" fill="#FFF3E0" stroke="black" stroke-width="2"/>
                        <text x="760" y="285" text-anchor="middle" fill="black" font-size="16">Conv2D</text>
                        <text x="760" y="305" text-anchor="middle" fill="black" font-size="14">1x1</text>
                        <text x="760" y="325" text-anchor="middle" fill="black" font-size="14">s=1</text>

                        <!-- Global Average Pooling -->
                        <rect x="860" y="250" width="100" height="100" rx="5" fill="#E3F2FD" stroke="black" stroke-width="2"/>
                        <text x="910" y="285" text-anchor="middle" fill="black" font-size="16">Global Avg</text>
                        <text x="910" y="305" text-anchor="middle" fill="black" font-size="14">Pooling</text>

                        <!-- Connections -->
                        <path d="M130 300 H180" stroke="black" stroke-width="2" marker-end="url(#arrowhead4)"/>
                        <path d="M280 300 H330" stroke="black" stroke-width="2" marker-end="url(#arrowhead4)"/>
                        <path d="M470 300 H520" stroke="black" stroke-width="2" marker-end="url(#arrowhead4)"/>
                        <path d="M660 300 H710" stroke="black" stroke-width="2" marker-end="url(#arrowhead4)"/>
                        <path d="M810 300 H860" stroke="black" stroke-width="2" marker-end="url(#arrowhead4)"/>
                    </svg>
                </div>
                <div class="architecture-description mt-4">
                    <h4>Key Components:</h4>
                    <ul>
                        <li><strong>Input Layer:</strong> Accepts 224×224×3 RGB images</li>
                        <li><strong>Initial Conv2D:</strong> 3×3 convolution with stride 2, 32 filters</li>
                        <li><strong>Bottleneck Block 1:</strong> First inverted residual block with expansion factor t=1, output channels c=16, n=1 layer, stride s=1</li>
                        <li><strong>Bottleneck Block 2:</strong> Second inverted residual block with t=6, c=24, n=2 layers, s=2</li>
                        <li><strong>Final Conv2D:</strong> 1×1 convolution to adjust channels</li>
                        <li><strong>Global Average Pooling:</strong> Reduces spatial dimensions to 1×1</li>
                    </ul>
                    <p class="mt-3">The MobileNetV2 architecture uses inverted residual blocks with linear bottlenecks as its core building blocks. Each block first expands the number of channels (t×), applies depthwise convolution, then projects back to a smaller number of channels. This structure allows efficient feature extraction while maintaining a small model size.</p>
                </div>
            </div>
        </div>
    </div>
    <script>
        $(document).ready(function() {
            // Get all model buttons and pages
            const modelButtons = $('.model-button');
            const modelPages = $('.model-page');

            // Add click event listener to each model button
            modelButtons.on('click', function() {
                // Remove active class from all buttons and pages
                modelButtons.removeClass('active');
                modelPages.removeClass('active');

                // Add active class to clicked button
                $(this).addClass('active');

                // Show corresponding model page
                const modelType = $(this).data('model');
                $(`#${modelType}-page`).addClass('active');
            });
        });
    </script>
</body>
</html>